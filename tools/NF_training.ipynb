{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weieric1001/nfsepsisanalysis/blob/main/tools/modelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DwEgzLUF9CjP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXEznUEM9CjR",
        "outputId": "e4b50392-54f2-4753-8b91-2d7eb52f4e9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "      sea    wbc     crp   seg  band  nf\n",
            "0       1  15000   26.38  91.5   8.0   1\n",
            "1       1  24100  174.27  83.0   2.0   1\n",
            "2       1   3500    1.94  60.0   2.0   1\n",
            "3       1  16500  191.54  88.8   0.0   1\n",
            "4       1  18600  137.31  79.5   7.0   1\n",
            "...   ...    ...     ...   ...   ...  ..\n",
            "1410    1   9500  110.58  83.0   0.0   0\n",
            "1411    0   7000    2.85  71.8   0.0   0\n",
            "1412    0   5900   21.04  75.0   0.0   0\n",
            "1413    1  14700   19.87  78.7   0.0   0\n",
            "1414    0   6700   15.98  66.2   0.0   0\n",
            "\n",
            "[1415 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "# 呼叫雲端硬碟\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# 讀取資料集\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/aa5.csv')\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "8arrPJNj9CjS",
        "outputId": "aec6d7f3-f593-441d-a6d4-59d0573087a2"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d960c9a45cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 讀取資料集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'document/aa5.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'document/aa5.csv'"
          ]
        }
      ],
      "source": [
        "# 讀取資料集\n",
        "df = pd.read_csv('document/aa5.csv')\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abT6ALWU9CjT",
        "outputId": "3b78e45c-d4b6-4647-c24a-e7ccff25b469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "資料集的描述：\n",
            "               sea            wbc          crp          seg         band  \\\n",
            "count  1415.000000    1415.000000  1415.000000  1415.000000  1415.000000   \n",
            "mean      0.178092   11340.508834    70.930066    75.215760     0.726007   \n",
            "std       0.382725    6256.728228    84.992794    11.570522     2.912236   \n",
            "min       0.000000    1100.000000     0.500000     5.300000     0.000000   \n",
            "25%       0.000000    7500.000000     8.115000    68.000000     0.000000   \n",
            "50%       0.000000   10100.000000    35.250000    77.000000     0.000000   \n",
            "75%       0.000000   14000.000000   110.080000    84.000000     0.000000   \n",
            "max       1.000000  108000.000000   709.310000    96.600000    31.500000   \n",
            "\n",
            "                nf  \n",
            "count  1415.000000  \n",
            "mean      0.122968  \n",
            "std       0.328517  \n",
            "min       0.000000  \n",
            "25%       0.000000  \n",
            "50%       0.000000  \n",
            "75%       0.000000  \n",
            "max       1.000000  \n"
          ]
        }
      ],
      "source": [
        "# 顯示資料集的描述資料\n",
        "print('資料集的描述：')\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI-7a5mFs0aN",
        "outputId": "03d15619-cc5a-4fd7-cae6-c5a91b04408c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sea         0.137931\n",
            "wbc     10877.586207\n",
            "crp        51.087874\n",
            "seg        74.245977\n",
            "band        0.266092\n",
            "dtype: float64\n",
            "sea        0.345823\n",
            "wbc     4898.568026\n",
            "crp       63.134101\n",
            "seg       11.010130\n",
            "band       1.293983\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "X_train = df.iloc[:, :5]\n",
        "Y_train = df.iloc[:, 5]\n",
        "X_train_class_0 = X_train[Y_train == 0]\n",
        "X_train_class_1 = X_train[Y_train == 1]\n",
        "X_train_class_0_under = X_train_class_0.sample(X_train_class_1.shape[0])\n",
        "X_train_mean = X_train_class_0_under.mean(axis=0)\n",
        "X_train_std = X_train_class_0_under.std(axis=0)\n",
        "print(X_train_mean)\n",
        "print(X_train_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A29Y4P5NsdzS",
        "outputId": "bcee2cc7-b8c4-46f9-9625-8354a188ebe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "資料集的資訊：\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1415 entries, 0 to 1414\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   sea     1415 non-null   int64  \n",
            " 1   wbc     1415 non-null   int64  \n",
            " 2   crp     1415 non-null   float64\n",
            " 3   seg     1415 non-null   float64\n",
            " 4   band    1415 non-null   float64\n",
            " 5   nf      1415 non-null   int64  \n",
            "dtypes: float64(3), int64(3)\n",
            "memory usage: 66.5 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# 顯示資料集的資訊\n",
        "print('資料集的資訊：')\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjIGBA2i9CjT",
        "outputId": "0fc9eb2a-b008-4d24-94ef-ad0a47f5bc98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "沒有資料的筆數：\n",
            "sea     0\n",
            "wbc     0\n",
            "crp     0\n",
            "seg     0\n",
            "band    0\n",
            "nf      0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 顯示沒有資料的筆數\n",
        "print('沒有資料的筆數：')\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxsCJCP89CjU",
        "outputId": "e72cdd80-2e6b-4955-80cc-bf3c93e99765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Rescaling ...\n",
            "X_train_final.shape：(348, 5)\n",
            "Y_train_final.shape：(348,)\n",
            "Training ...\n",
            "Testing ...\n",
            "Decision tree 訓練資料集的準確度 = 0.8477\n"
          ]
        }
      ],
      "source": [
        "# 資料處理1 Decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "clf = DecisionTreeClassifier(\n",
        "    criterion='entropy', max_depth=5, min_samples_leaf=9)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 編碼後的X與Y\n",
        "X_train = df.iloc[:, :5]\n",
        "Y_train = df.iloc[:, 5]\n",
        "\n",
        "# Class count\n",
        "count_class_0, count_class_1 = Y_train.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "X_train_class_0 = X_train[Y_train == 0]\n",
        "X_train_class_1 = X_train[Y_train == 1]\n",
        "X_train_class_0_under = X_train_class_0.sample(\n",
        "    X_train_class_1.shape[0])  # 174\n",
        "X_train_under = pd.concat([X_train_class_0_under, X_train_class_1], axis=0)\n",
        "X_train_final = X_train_under\n",
        "Y_train_final = Y_train[X_train_under.index]\n",
        "\n",
        "# 資料標準化\n",
        "print(\"Data Rescaling ...\")\n",
        "X_train_final = pd.DataFrame(scaler.fit_transform(X_train_final))\n",
        "print('X_train_final.shape：{}'.format(X_train_final.shape))\n",
        "print('Y_train_final.shape：{}'.format(Y_train_final.shape))\n",
        "\n",
        "# 訓練模型1 Decision tree\n",
        "print(\"Training ...\")\n",
        "clf.fit(X_train_final, Y_train_final)\n",
        "\n",
        "# 評估模型1 Decision tree\n",
        "print(\"Testing ...\")\n",
        "# 計算訓練資料集的準確度\n",
        "accuracy = clf.score(X_train_final, Y_train_final)\n",
        "print(\"Decision tree 訓練資料集的準確度 = {:.4f}\".format(accuracy))\n",
        "\n",
        "# 儲存模型\n",
        "model_file_name = 'model/decisionTree.pickle'\n",
        "with open(model_file_name, 'wb') as f:\n",
        "    pickle.dump(clf, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwUhvdju9CjV",
        "outputId": "d7b040db-24fa-4d39-bbc0-2cbc3bfcaabf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Rescaling ...\n",
            "X_train_final.shape：(348, 5)\n",
            "Y_train_final.shape：(348,)\n",
            "Training ...\n",
            "Testing ...\n",
            "Random forest 訓練資料集的準確度 = 1.0000\n"
          ]
        }
      ],
      "source": [
        "# 資料處理2 Random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=750, max_depth=20, criterion='entropy', max_features='sqrt')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 編碼後的X與Y\n",
        "X_train = df.iloc[:, :5]\n",
        "Y_train = df.iloc[:, 5]\n",
        "\n",
        "# Class count\n",
        "count_class_0, count_class_1 = Y_train.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "X_train_class_0 = X_train[Y_train == 0]\n",
        "X_train_class_1 = X_train[Y_train == 1]\n",
        "X_train_class_0_under = X_train_class_0.sample(\n",
        "    X_train_class_1.shape[0])  # 174\n",
        "X_train_under = pd.concat([X_train_class_0_under, X_train_class_1], axis=0)\n",
        "X_train_final = X_train_under\n",
        "Y_train_final = Y_train[X_train_under.index]\n",
        "\n",
        "# 資料標準化\n",
        "print(\"Data Rescaling ...\")\n",
        "X_train_final = pd.DataFrame(scaler.fit_transform(X_train_final))\n",
        "print('X_train_final.shape：{}'.format(X_train_final.shape))\n",
        "print('Y_train_final.shape：{}'.format(Y_train_final.shape))\n",
        "\n",
        "# 訓練模型2 Random forest\n",
        "print(\"Training ...\")\n",
        "rf.fit(X_train_final, Y_train_final)\n",
        "\n",
        "# 評估模型2 Random forest\n",
        "print(\"Testing ...\")\n",
        "# 計算訓練資料集的準確度\n",
        "accuracy = rf.score(X_train_final, Y_train_final)\n",
        "print(\"Random forest 訓練資料集的準確度 = {:.4f}\".format(accuracy))\n",
        "\n",
        "# 儲存模型\n",
        "model_file_name = 'model/randomForest.pickle'\n",
        "with open(model_file_name, 'wb') as f:\n",
        "    pickle.dump(rf, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLVTn4vj9CjW",
        "outputId": "04a020be-7b6f-476d-f353-04c431bcbe90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Rescaling ...\n",
            "sea         0.255747\n",
            "wbc     12546.839080\n",
            "crp       101.779655\n",
            "seg        77.377299\n",
            "band        2.160057\n",
            "dtype: float64\n",
            "sea        0.436909\n",
            "wbc     6951.471663\n",
            "crp      102.112756\n",
            "seg       11.340239\n",
            "band       5.126581\n",
            "dtype: float64\n",
            "X_train_final.shape：(348, 5)\n",
            "Y_train_final.shape：(348,)\n",
            "Training ...\n",
            "Testing ...\n",
            "Logistic Regression 訓練資料集的準確度 = 0.8333\n"
          ]
        }
      ],
      "source": [
        "# 資料處理3 Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "logreg = LogisticRegression(penalty='l2', C=0.01)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 編碼後的X與Y\n",
        "X_train = df.iloc[:, :5]\n",
        "Y_train = df.iloc[:, 5]\n",
        "\n",
        "# Class count\n",
        "count_class_0, count_class_1 = Y_train.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "X_train_class_0 = X_train[Y_train == 0]\n",
        "X_train_class_1 = X_train[Y_train == 1]\n",
        "X_train_class_0_under = X_train_class_0.sample(\n",
        "    X_train_class_1.shape[0])  # 174\n",
        "X_train_under = pd.concat([X_train_class_0_under, X_train_class_1], axis=0)\n",
        "X_train_final = X_train_under\n",
        "Y_train_final = Y_train[X_train_under.index]\n",
        "\n",
        "# 資料標準化\n",
        "print(\"Data Rescaling ...\")\n",
        "X_train_mean = X_train_final.mean(axis=0)\n",
        "X_train_std = X_train_final.std(axis=0)\n",
        "print(X_train_mean)\n",
        "print(X_train_std)\n",
        "X_train_final = pd.DataFrame(scaler.fit_transform(X_train_final))\n",
        "print('X_train_final.shape：{}'.format(X_train_final.shape))\n",
        "print('Y_train_final.shape：{}'.format(Y_train_final.shape))\n",
        "\n",
        "# 訓練模型3 Logistic Regression\n",
        "print(\"Training ...\")\n",
        "logreg.fit(X_train_final, Y_train_final)\n",
        "\n",
        "# 評估模型3 Logistic Regression\n",
        "print(\"Testing ...\")\n",
        "# 計算訓練資料集的準確度\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
        "accuracy = logreg.score(X_train_final, Y_train_final)\n",
        "print(\"Logistic Regression 訓練資料集的準確度 = {:.4f}\".format(accuracy))\n",
        "\n",
        "# 儲存模型\n",
        "model_file_name = 'logisticregression.pickle'\n",
        "with open(model_file_name, 'wb') as f:\n",
        "    pickle.dump(logreg, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHWE96Jv9CjW",
        "outputId": "32cd9572-307a-475c-90b4-016063d3a22b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Rescaling ...\n",
            "sea         0.238506\n",
            "wbc     12409.252874\n",
            "crp        96.047414\n",
            "seg        77.022701\n",
            "band        2.236782\n",
            "dtype: float64\n",
            "sea        0.426784\n",
            "wbc     6895.573196\n",
            "crp      101.699342\n",
            "seg       10.816080\n",
            "band       5.159527\n",
            "dtype: float64\n",
            "X_train_final.shape：(348, 5)\n",
            "Y_train_final.shape：(348,)\n",
            "Training ...\n",
            "Testing ...\n",
            "Support Vector Machine 訓練資料集的準確度 = 0.8190\n"
          ]
        }
      ],
      "source": [
        "# 資料處理5 Support Vector Machine\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "model = SVC(kernel='rbf', C=10, gamma=0.0001, cache_size=1000, probability=True)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 編碼後的X與Y\n",
        "X_train = df.iloc[:, :5]\n",
        "Y_train = df.iloc[:, 5]\n",
        "\n",
        "# Class count\n",
        "count_class_0, count_class_1 = Y_train.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "print(\"Data Rescaling ...\")\n",
        "X_train_class_0 = X_train[Y_train == 0]\n",
        "X_train_class_1 = X_train[Y_train == 1]\n",
        "X_train_class_0_under = X_train_class_0.sample(\n",
        "    X_train_class_1.shape[0])  # 174\n",
        "X_train_under = pd.concat([X_train_class_0_under, X_train_class_1], axis=0)\n",
        "X_train_final = X_train_under\n",
        "Y_train_final = Y_train[X_train_under.index]\n",
        "\n",
        "# 資料標準化\n",
        "X_train_mean = X_train_final.mean(axis=0)\n",
        "X_train_std = X_train_final.std(axis=0)\n",
        "print(X_train_mean)\n",
        "print(X_train_std)\n",
        "X_train_final = pd.DataFrame(scaler.fit_transform(X_train_final))\n",
        "print('X_train_final.shape：{}'.format(X_train_final.shape))\n",
        "print('Y_train_final.shape：{}'.format(Y_train_final.shape))\n",
        "\n",
        "# 訓練模型5 Support Vector Machine\n",
        "print(\"Training ...\")\n",
        "model.fit(X_train_final, Y_train_final)\n",
        "\n",
        "# 評估模型5 Support Vector Machine\n",
        "print(\"Testing ...\")\n",
        "# 計算訓練資料集的準確度\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
        "accuracy = model.score(X_train_final, Y_train_final)\n",
        "print(\"Support Vector Machine 訓練資料集的準確度 = {:.4f}\".format(accuracy))\n",
        "\n",
        "# 儲存模型\n",
        "model_file_name = 'supportVectorMachine.pickle'\n",
        "with open(model_file_name, 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBY6LER69CjX",
        "outputId": "f86a9873-d0e7-412d-e701-5213a1bfc6c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "全部資料集的準確度 = 0.7074\n"
          ]
        }
      ],
      "source": [
        "# 讀取模型\n",
        "# model_file_name = 'model/decisionTree.pickle'\n",
        "# model_file_name = 'model/randomForest.pickle'\n",
        "# model_file_name = 'model/logisticregression.pickle'\n",
        "# model_file_name = 'model/supportVectorMachine.pickle'\n",
        "with open(model_file_name, 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "X = df.iloc[:, :5]\n",
        "Y = df.iloc[:, 5]\n",
        "\n",
        "# 計算全部資料集的準確度\n",
        "X = pd.DataFrame(scaler.fit_transform(X))\n",
        "accuracy = model.score(X, Y)\n",
        "print(\"全部資料集的準確度 = {:.4f}\".format(accuracy))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.10 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9d1af5a4960a96d7621722435ce13e2a5fde01041db7fd0603c44397b4f28380"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
